{
  "5": {
    "inputs": {
      "width": 512,
      "height": 768,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": "masterpiece, best quality, absurdres, 1boy, blonde hair, blue eyes, kira yoshikage, business suit, collared shirt, necktie, purple jacket, purple pants, long sleeves, upper body, pants, suitcase, portrait, araki hirohiko (style)",
      "clip": [
        "22",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), out of frame, extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), (((lowres))), (worst quality, low quality:1.3), (3D:1.3), signature, watermark, username, artist name",
      "clip": [
        "22",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "28",
        0
      ],
      "vae": [
        "33",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "11": {
    "inputs": {
      "images": [
        "8",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "14": {
    "inputs": {
      "ckpt_name": "DreamShaper8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "15": {
    "inputs": {
      "b1": 1.3,
      "b2": 1.6,
      "s1": 0.9,
      "s2": 0.2,
      "model": [
        "22",
        0
      ]
    },
    "class_type": "FreeU_V2",
    "_meta": {
      "title": "FreeU_V2"
    }
  },
  "17": {
    "inputs": {
      "samples": [
        "27",
        0
      ],
      "vae": [
        "33",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "18": {
    "inputs": {
      "images": [
        "17",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "22": {
    "inputs": {
      "lora_01": "lcm/SD1.5/pytorch_lora_weights.safetensors",
      "strength_01": 1,
      "lora_02": "pixel sprites.safetensors",
      "strength_02": 0.3,
      "lora_03": "diamond_wa_kudakenai_2.safetensors",
      "strength_03": 1,
      "lora_04": "None",
      "strength_04": 1,
      "model": [
        "14",
        0
      ],
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "Lora Loader Stack (rgthree)",
    "_meta": {
      "title": "Lora Loader Stack (rgthree)"
    }
  },
  "25": {
    "inputs": {
      "sampling": "lcm",
      "zsnr": false,
      "model": [
        "22",
        0
      ]
    },
    "class_type": "ModelSamplingDiscrete",
    "_meta": {
      "title": "ModelSamplingDiscrete"
    }
  },
  "26": {
    "inputs": {
      "sampling": "lcm",
      "zsnr": false,
      "model": [
        "15",
        0
      ]
    },
    "class_type": "ModelSamplingDiscrete",
    "_meta": {
      "title": "ModelSamplingDiscrete"
    }
  },
  "27": {
    "inputs": {
      "seed": 226007535086801,
      "steps": 4,
      "cfg": 1.3,
      "sampler_name": "lcm",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "26",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "28": {
    "inputs": {
      "seed": 226007535086801,
      "steps": 4,
      "cfg": 1.3,
      "sampler_name": "lcm",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "25",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "29": {
    "inputs": {
      "pixel_size": 4,
      "image": [
        "17",
        0
      ]
    },
    "class_type": "Pixelization",
    "_meta": {
      "title": "Pixelization"
    }
  },
  "30": {
    "inputs": {
      "images": [
        "29",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "31": {
    "inputs": {
      "pixel_size": 4,
      "image": [
        "8",
        0
      ]
    },
    "class_type": "Pixelization",
    "_meta": {
      "title": "Pixelization"
    }
  },
  "32": {
    "inputs": {
      "images": [
        "31",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "33": {
    "inputs": {
      "vae_name": "wd.vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  }
}